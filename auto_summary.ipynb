{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-02 23:26:37,130 : MainThread : INFO : loading projection weights from data/small_ailab_embedding.txt\n",
      "2020-04-02 23:27:12,271 : MainThread : INFO : loaded (206389, 200) matrix from data/small_ailab_embedding.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "无症状感染者恐引第二波疫情？专家：不是主因，关键看4月底\n",
      "(46, 1)\n",
      "(46,)\n",
      "--;"
     ]
    },
    {
     "data": {
      "text/html": [
       "<font  color=\"forestgreen\" >新冠肺炎疫情暴发以来，频繁出现的无症状感染者病例，再次引起恐慌。</font><font style=\"background-color:red\" >近日，国家卫健委首度公布无症状感染者的情况。</font><font style=\"background-color:red\" >截至3月31日24时，31个省（自治区、直辖市）和新疆生产建设兵团报告新增无症状感染者130例，当日转为确诊病例2例，当日解除隔离302例。</font><font  color=\"sandybrown\" >尚在医学观察无症状感染者1367例，比前一日减少174例。</font><font  color=\"chocolate\" >那么，到底谁是无症状感染者？</font><font  color=\"chocolate\" >这些隐匿的感染者还有多少？</font><font  color=\"forestgreen\" >会不会引爆第二波疫情？</font><font style=\"background-color:red\" >香港大学李嘉诚医学院教授高本恩告诉《中国科学报》：“第二波疫情是否到来关键看4月底，但无症状感染者不是主因。”</font><font  color=\"darkkhaki\" >谁是“无症状感染者”？</font><font style=\"background-color:red\" >3月31日，国务院新闻办召开的发布会上公布了无症状感染者的最新定义，即无发烧、咳嗽、咽痛等自我感知临床症状、无临床可识别症状体征，但呼吸道等样本病原学检测为阳性的患者。</font><font  color=\"darkkhaki\" >对比国家卫健委3月7日在《新型冠状病毒肺炎防控方案（第六版）》中的定义，新定义增加了“自我感知”和“可识别症状”等主观感受方面的限定条件。</font><font  color=\"darkkhaki\" >过去一段时间，从新冠肺炎疫情发生初期，随着无症状感染者陆续在各地被通报，引发科技界高度关注和重视，并围绕其如何定义展开讨论。</font><font  color=\"firebrick\" >1月29日，浙江杭州首次发现一名无症状感染者。</font><font  color=\"chocolate\" >《中国科学报》采访中，专家表示，这的确刷新了专业人士和公众认知。</font><font style=\"background-color:red\" >中国工程院院士闻玉梅在当时的采访中强调了对无症状感染者的界定：“不发烧不等于没有症状，或者症状较轻容易被忽略。”</font><font  color=\"forestgreen\" >“一定要非常慎重，不要因为误判引发恐慌。”</font><font  color=\"darkkhaki\" >美国麻省大学医学院教授卢山也指出，证实感染者的确无症状，需要排除检测方法的假阳性、采集样本和检测中的交叉污染以及数据的可重复性等。</font><font style=\"background-color:red\" >3月29日，国家卫健委专家组成员、北京地坛医院感染二科主任医师蒋荣猛在其个人微信公众号“北京也云感染”上发表文章称，即使是报告的“无症状感染者”，也可能存在因为症状轻微或不能正常主诉（如失语的老年人、儿童等）或因基础疾病如心血管疾病、慢性肺部疾病等症状的干扰导致信息采集偏离，同时也有客观证据显示部分“无症状感染者”其实有胸部X线检查异常表现。</font><font style=\"background-color:red\" >3月31日，美国加州大学洛杉矶分校公共卫生学院副院长张作风接受《财经》采访时，仍然强调了排除主观因素重要性：病人在报告时可能会忽略胃痛、腹泻等症状，而这些有可能是感染新冠病毒的早期症状。</font><font  color=\"darkorchid\" >此前，一篇发表在《新英格兰医学杂志》上的论文就闹了“乌龙”。</font><font  color=\"violet\" >研究者报道了德国首次发现新冠病毒，病人是一位来自上海的当时无症状感染者。</font><font  color=\"violet\" >几天后，研究者致函杂志，澄清了事实：作者在发表这篇论文之前并没有真正与这位女士沟通，信息仅来源于德国四位患者的口述，即“这位上海女同事似乎没有症状”。</font><font  color=\"violet\" >这名病人事实上出现了症状，她感到乏力、肌肉疼痛，并服用了退烧药扑热息痛。</font><font  color=\"mediumblue\" >新增限定条件围绕患者主观感受，回应了此前科学家们的担忧，让无症状感染者的统计在研究和防控方面更精准、更有针对性。</font><font  color=\"palevioletred\" >“冰山一角”将致第二波暴发？</font><font style=\"background-color:red\" >2月5日，国家卫健委发布《新型冠状病毒感染的肺炎诊疗方案（试行第五版）》，首次提出“无症状感染者也可能成为传染源”。</font><font  color=\"chocolate\" >蒋荣猛在公号文章中介绍：“从传染病的规律看，传染病流行通常有两个‘冰山’现象，即第一个冰山现象是感染后发病的是少数人，这也是为何要开展传染病报告、流行病学调查、密切接触者追踪的主要原因所在。</font><font  color=\"chocolate\" >第二个冰山现象是感染后发病人群中重症的比例占少数。”</font><font  color=\"palevioletred\" >在全国各地已经吹响复工复产号角的当下，人们担忧的是，“无症状感染者”会不会是第三个“冰山”——无症状感染者会不会在人群中占有不小的比例？</font><font  color=\"chocolate\" >他们携带病毒自由行动，正像隐匿的病毒传播者，最终导致疫情第二波暴发。</font><font  color=\"palevioletred\" >多项科学研究围绕这个问题展开。</font><font  color=\"antuquewhite\" >例如，美国乔治亚州立大学流行病学家Gerardo Chowell等学者3月曾在《欧洲监测》上发表研究，其对“钻石公主”号患者的模型统计显示，无症状患者比例为17.9%。</font><font  color=\"mediumblue\" >对此，蒋荣猛在前述公号文章中指出，“钻石公主”号只是一个特例。</font><font  color=\"darkorchid\" >华中科技大学公共卫生学院教授邬堂春等学者，曾对武汉卫健委法定传染病报告系统中的确诊数据进行建模，得出武汉市至少有59%感染病例未被发现，其中包括无症状感染者和轻症患者。</font><font  color=\"firebrick\" >他在接受媒体采访时解释，该结果是基于“最保守的模型预测”，并未进行实地流行病学调查。</font><font style=\"background-color:red\" >而据中国疾控中心2月17日在《中华流行病学》杂志上超7万人的大样本分析，889名无症状感染者占总数的1.2%。</font><font style=\"background-color:red\" >中国工程院院士钟南山受访时，通过从结果反推的方式否定了无症状感染者“冰山一角”的担忧。</font><font  color=\"violet\" >他表示，无症状感染者对密切接触者传染率较高，而中国近期新增确诊病例数未升反降，据此可以推断，中国还没有大量的无症状感染者。</font><font  color=\"antuquewhite\" >“历次疫情和疾病流行中都有无症状感染者出现，但这并非疫情再度暴发的诱因。”</font><font  color=\"chocolate\" >高本恩告诉《中国科学报》，“COVID-19最早在武汉出现是2019年12月初，大约1个月后才真正得到确认。</font><font style=\"background-color:red\" >其他国家的情况是，从2020年1月下旬输入性感染到2月下旬确认的社区感染，也大约是1个月。</font><font  color=\"forestgreen\" >这样看来，未能严格控制境外输入病例、未能维持社区隔离才是可能导致疫情二次暴发的关键。</font><font  color=\"firebrick\" >高本恩据此推测，当前措施的效果会在4月底前后显示出来。</font><font  color=\"darkkhaki\" >浙江大学医学院公共卫生系教授金永堂告诉《中国科学报》：“没有证据表明我国存在二次暴发疫情和无症状感染者引发的疫情问题，否则我国本次疫情暴发与大流行不会如期得到顺利控制。”</font><font  color=\"forestgreen\" >（原标题为《 “无症状”恐引第二波疫情？</font><font  color=\"mediumblue\" >专家表示不是主因》）</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "import pkuseg\n",
    "import networkx as nx\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from pyltp import SentenceSplitter\n",
    "import logging\n",
    "import re\n",
    "from sklearn.preprocessing import  MinMaxScaler\n",
    "from IPython.display import display, HTML\n",
    "logging.basicConfig(format='%(asctime)s : %(threadName)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "seg = pkuseg.pkuseg(postag=True)\n",
    "with open('data/stopwords.txt', 'r',encoding='utf8') as f:\n",
    "    stopwords = set([w.strip() for w in f])\n",
    "small_vec_model = KeyedVectors.load_word2vec_format('data/small_ailab_embedding.txt')\n",
    "\n",
    "def split_document(document):\n",
    "    return [sen for sen in SentenceSplitter.split(document) if sen]\n",
    "\n",
    "\n",
    "def query(words):\n",
    "    # exist_words = list(filter(lambda x: x in self.vector_from_text, words))\n",
    "    # non_exist_words = [i for i in words if i not in self.vector_from_text]\n",
    "    # if non_exist_words:\n",
    "    #     chars = list(filter(lambda x: x in self.vector_from_text, ''.join(non_exist_words)))\n",
    "    #     exist_words += chars\n",
    "    words = [w for w in words if w in small_vec_model]\n",
    "    words_vector = np.mean([small_vec_model[w] for w in words], axis=0) \\\n",
    "        if words else np.zeros(small_vec_model.vector_size)\n",
    "    return words_vector\n",
    "\n",
    "\n",
    "def split_func(string):\n",
    "    useful_words = [word for word,flag in seg.cut(string) if flag.startswith('n') or flag.startswith('v')]\n",
    "    return useful_words\n",
    "\n",
    "\n",
    "def get_sentnce_vector(all_sentences_words):\n",
    "    sentence_vec = np.array([query(words) for words in all_sentences_words])\n",
    "    return sentence_vec\n",
    "\n",
    "\n",
    "def calc_page_rank(sentence_vec):\n",
    "    sim_mat = cosine_similarity(sentence_vec)\n",
    "    np.fill_diagonal(sim_mat, 0)\n",
    "    nx_graph = nx.from_numpy_array(sim_mat)\n",
    "    tol, max_iter = 1e-7, 1000\n",
    "    Flag = True\n",
    "    while Flag:\n",
    "        try:\n",
    "            pagerank_score = nx.pagerank(nx_graph, tol=tol, max_iter=max_iter)\n",
    "            Flag = False\n",
    "        except nx.PowerIterationFailedConvergence as e:\n",
    "            print(e)\n",
    "            tol *= 10\n",
    "    pagerank_score = np.array([v for k, v in sorted(pagerank_score.items(), key=lambda x: x[0])])\n",
    "    return pagerank_score\n",
    "\n",
    "\n",
    "def get_title_similarity(sentence_vec, title_vec):\n",
    "#     title_vector = get_sentnce_vector(title)\n",
    "    sim_mat = cosine_similarity(sentence_vec,title_vec)\n",
    "    return sim_mat\n",
    "\n",
    "def get_title_common_score(all_sentences_words, title_words):\n",
    "    set_title_words = set(title_words)    \n",
    "    ret = []\n",
    "    for words in all_sentences_words:\n",
    "        set_words = set(words)& set_title_words\n",
    "        if len(set_words)>=2:\n",
    "            ret.append(1.5)\n",
    "        else:\n",
    "            ret.append(1)\n",
    "    return np.array(ret)\n",
    "\n",
    "\n",
    "def get_position_score(sen_length):\n",
    "    position_score = np.ones(sen_length)\n",
    "    position_score[1] = 2 \n",
    "    position_score[-1] = 1.3\n",
    "    return position_score\n",
    "\n",
    "def have_date(sentence):\n",
    "    if re.findall('[0-9去上前明后]{1,4}年', sentence):\n",
    "        return True\n",
    "    if re.findall('[0-9上个一二三四五六七八九十]{1,2}月', sentence):\n",
    "        return True\n",
    "    if re.findall('[0-9上昨前]{1,4}日', sentence):\n",
    "        return True\n",
    "    if re.findall('[昨|前]天', sentence):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "with open('data/important_people_orgnazation.txt', 'r', encoding='utf8') as f:\n",
    "    people_org_set = set()\n",
    "    for line in f:\n",
    "        words = line.strip().split(';')\n",
    "        people_org_set.update(words)\n",
    "\n",
    "\n",
    "def have_important_org_peo(sentence):\n",
    "    for entity in people_org_set:\n",
    "        if entity in sentence:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def get_entities_score(sentence):\n",
    "    date_score = int(have_date(sentence))\n",
    "    ple_org_score = int(have_important_org_peo(sentence))\n",
    "    return 1.6 if (date_score + ple_org_score) > 0 else 1\n",
    "\n",
    "def get_clue_score(sentences):\n",
    "    clue_words = '总之 总而言之 综上 综上所述 一言以蔽之 概括起来说 括而言之 括而言之 要而论之 统而言之 归根到底 归根结底 简而言之'.split()\n",
    "    result = []\n",
    "    for sen in sentences:\n",
    "        flag = 1\n",
    "        for w in clue_words:\n",
    "            if w in sen:\n",
    "                flag = 1.4\n",
    "                break\n",
    "        result.append(flag)\n",
    "    return np.array(result)\n",
    "        \n",
    "def auto_summary(doc,title,extract_num=None,title_common=False,use_mmr=True):\n",
    "    sentences = split_document(doc)\n",
    "    len_sen = len(sentences)\n",
    "    if len_sen < 8:\n",
    "        print(len_sen, end=';')\n",
    "        return ''\n",
    "    all_sentences_words = [split_func(sen) for sen in sentences]\n",
    "    sentence_vec = get_sentnce_vector(all_sentences_words)\n",
    "    pagerank_score = calc_page_rank(sentence_vec)\n",
    "    entities_score = np.array([get_entities_score(sen) for sen in sentences])\n",
    "    \n",
    "    title_words = split_func(title)\n",
    "    title_vec = get_sentnce_vector([title_words])\n",
    "    title_common_score = get_title_common_score(all_sentences_words, title_words)\n",
    "    title_sim_score = get_title_similarity(sentence_vec, title_vec)\n",
    "    scaler = MinMaxScaler((1,2))\n",
    "    scaler.fit(title_sim_score)\n",
    "\n",
    "#     print(scaler.data_max_)\n",
    "    print(title_sim_score.shape)\n",
    "    title_sim_score = scaler.transform(title_sim_score)[:,0]\n",
    "    print(title_sim_score.shape)\n",
    "    position_score = get_position_score(len_sen)\n",
    "    clue_score = get_clue_score(sentences)\n",
    "    score = pagerank_score * entities_score * (title_common_score if title_common else title_sim_score) * position_score * clue_score\n",
    "    if extract_num is None:\n",
    "        extract_num = max(5, len_sen // 2)\n",
    "        extract_num = min(extract_num, 23)\n",
    "    #----------------MMR-------------------------------------\n",
    "    n = extract_num\n",
    "    summary_set = []\n",
    "    alpha = 0.8\n",
    "    max_score_index = np.argmax(score)\n",
    "    summary_set.append(max_score_index)\n",
    "    while n > 0:\n",
    "        sim_mat = cosine_similarity(sentence_vec,sentence_vec[summary_set])\n",
    "        sim_mat = np.max(sim_mat,axis=1)\n",
    "        import pdb\n",
    "#         pdb.set_trace()\n",
    "        scaler = MinMaxScaler()\n",
    "        feature_score = np.array([score,sim_mat]).T\n",
    "        scaler.fit(feature_score)\n",
    "        feature_score = scaler.transform(feature_score)\n",
    "        [score,sim_mat] = feature_score[:,0], feature_score[:,1]\n",
    "        mmr_score =  alpha*score - (1-alpha)*sim_mat\n",
    "        mmr_score[summary_set] = -100\n",
    "        max_index  = np.argmax(mmr_score)\n",
    "        summary_set.append(max_index)\n",
    "        n -= 1\n",
    "    #----------------MMR-------------------------------------\n",
    "    if not use_mmr:\n",
    "        pagerank_sort = sorted(list(enumerate(score)), key=lambda x: x[1], reverse=True)[:extract_num]\n",
    "        rank_keys = [k for k, v in pagerank_sort]\n",
    "    else:\n",
    "        rank_keys = summary_set\n",
    "    color_list = ['firebrick','palevioletred','darkorchid','violet','chocolate','sandybrown','antuquewhite','darkkhaki','forestgreen','mediumblue']\n",
    "    summary = ''.join([sen for idx, sen in enumerate(sentences) if idx in rank_keys])\n",
    "    template = '<font style=\"background-color:{}\" >{}</font>'\n",
    "    template_normal = '<font  color=\"{}\" >{}</font>'\n",
    "    html_summary = ''.join([template.format('red',sen) if idx in rank_keys else template_normal.format(random.choice(color_list),sen)\n",
    "                            for idx, sen in enumerate(sentences)])\n",
    "    print('--',end=';')\n",
    "    feature_df = pd.DataFrame({k:v for v,k in zip([score,pagerank_score,entities_score, title_sim_score, position_score,clue_score,sentences],\n",
    "                              ['score','pagerank_score','entities_score', 'title_sim_score', 'position_score','clue_score','sentences'])}\n",
    "                             )\n",
    "    return summary, html_summary,(sentences, score),feature_df\n",
    "\n",
    "\n",
    "content = \"\"\"\n",
    "新冠肺炎疫情暴发以来，频繁出现的无症状感染者病例，再次引起恐慌。近日，国家卫健委首度公布无症状感染者的情况。截至3月31日24时，31个省（自治区、直辖市）和新疆生产建设兵团报告新增无症状感染者130例，当日转为确诊病例2例，当日解除隔离302例。尚在医学观察无症状感染者1367例，比前一日减少174例。\n",
    "\n",
    "那么，到底谁是无症状感染者？这些隐匿的感染者还有多少？会不会引爆第二波疫情？香港大学李嘉诚医学院教授高本恩告诉《中国科学报》：“第二波疫情是否到来关键看4月底，但无症状感染者不是主因。”\n",
    "\n",
    "谁是“无症状感染者”？\n",
    "\n",
    "3月31日，国务院新闻办召开的发布会上公布了无症状感染者的最新定义，即无发烧、咳嗽、咽痛等自我感知临床症状、无临床可识别症状体征，但呼吸道等样本病原学检测为阳性的患者。\n",
    "\n",
    "对比国家卫健委3月7日在《新型冠状病毒肺炎防控方案（第六版）》中的定义，新定义增加了“自我感知”和“可识别症状”等主观感受方面的限定条件。过去一段时间，从新冠肺炎疫情发生初期，随着无症状感染者陆续在各地被通报，引发科技界高度关注和重视，并围绕其如何定义展开讨论。\n",
    "\n",
    "1月29日，浙江杭州首次发现一名无症状感染者。《中国科学报》采访中，专家表示，这的确刷新了专业人士和公众认知。\n",
    "\n",
    "中国工程院院士闻玉梅在当时的采访中强调了对无症状感染者的界定：“不发烧不等于没有症状，或者症状较轻容易被忽略。”“一定要非常慎重，不要因为误判引发恐慌。”\n",
    "\n",
    "美国麻省大学医学院教授卢山也指出，证实感染者的确无症状，需要排除检测方法的假阳性、采集样本和检测中的交叉污染以及数据的可重复性等。\n",
    "\n",
    "3月29日，国家卫健委专家组成员、北京地坛医院感染二科主任医师蒋荣猛在其个人微信公众号“北京也云感染”上发表文章称，即使是报告的“无症状感染者”，也可能存在因为症状轻微或不能正常主诉（如失语的老年人、儿童等）或因基础疾病如心血管疾病、慢性肺部疾病等症状的干扰导致信息采集偏离，同时也有客观证据显示部分“无症状感染者”其实有胸部X线检查异常表现。\n",
    "\n",
    "3月31日，美国加州大学洛杉矶分校公共卫生学院副院长张作风接受《财经》采访时，仍然强调了排除主观因素重要性：病人在报告时可能会忽略胃痛、腹泻等症状，而这些有可能是感染新冠病毒的早期症状。\n",
    "\n",
    "此前，一篇发表在《新英格兰医学杂志》上的论文就闹了“乌龙”。研究者报道了德国首次发现新冠病毒，病人是一位来自上海的当时无症状感染者。\n",
    "\n",
    "几天后，研究者致函杂志，澄清了事实：作者在发表这篇论文之前并没有真正与这位女士沟通，信息仅来源于德国四位患者的口述，即“这位上海女同事似乎没有症状”。这名病人事实上出现了症状，她感到乏力、肌肉疼痛，并服用了退烧药扑热息痛。\n",
    "\n",
    "新增限定条件围绕患者主观感受，回应了此前科学家们的担忧，让无症状感染者的统计在研究和防控方面更精准、更有针对性。\n",
    "\n",
    "“冰山一角”将致第二波暴发？\n",
    "\n",
    "2月5日，国家卫健委发布《新型冠状病毒感染的肺炎诊疗方案（试行第五版）》，首次提出“无症状感染者也可能成为传染源”。\n",
    "\n",
    "蒋荣猛在公号文章中介绍：“从传染病的规律看，传染病流行通常有两个‘冰山’现象，即第一个冰山现象是感染后发病的是少数人，这也是为何要开展传染病报告、流行病学调查、密切接触者追踪的主要原因所在。第二个冰山现象是感染后发病人群中重症的比例占少数。”\n",
    "\n",
    "在全国各地已经吹响复工复产号角的当下，人们担忧的是，“无症状感染者”会不会是第三个“冰山”——无症状感染者会不会在人群中占有不小的比例？他们携带病毒自由行动，正像隐匿的病毒传播者，最终导致疫情第二波暴发。\n",
    "\n",
    "多项科学研究围绕这个问题展开。例如，美国乔治亚州立大学流行病学家Gerardo Chowell等学者3月曾在《欧洲监测》上发表研究，其对“钻石公主”号患者的模型统计显示，无症状患者比例为17.9%。对此，蒋荣猛在前述公号文章中指出，“钻石公主”号只是一个特例。\n",
    "\n",
    "华中科技大学公共卫生学院教授邬堂春等学者，曾对武汉卫健委法定传染病报告系统中的确诊数据进行建模，得出武汉市至少有59%感染病例未被发现，其中包括无症状感染者和轻症患者。他在接受媒体采访时解释，该结果是基于“最保守的模型预测”，并未进行实地流行病学调查。\n",
    "\n",
    "而据中国疾控中心2月17日在《中华流行病学》杂志上超7万人的大样本分析，889名无症状感染者占总数的1.2%。\n",
    "\n",
    "中国工程院院士钟南山受访时，通过从结果反推的方式否定了无症状感染者“冰山一角”的担忧。他表示，无症状感染者对密切接触者传染率较高，而中国近期新增确诊病例数未升反降，据此可以推断，中国还没有大量的无症状感染者。\n",
    "\n",
    "“历次疫情和疾病流行中都有无症状感染者出现，但这并非疫情再度暴发的诱因。”高本恩告诉《中国科学报》，“COVID-19最早在武汉出现是2019年12月初，大约1个月后才真正得到确认。其他国家的情况是，从2020年1月下旬输入性感染到2月下旬确认的社区感染，也大约是1个月。这样看来，未能严格控制境外输入病例、未能维持社区隔离才是可能导致疫情二次暴发的关键。\n",
    "\n",
    "高本恩据此推测，当前措施的效果会在4月底前后显示出来。\n",
    "\n",
    "浙江大学医学院公共卫生系教授金永堂告诉《中国科学报》：“没有证据表明我国存在二次暴发疫情和无症状感染者引发的疫情问题，否则我国本次疫情暴发与大流行不会如期得到顺利控制。”\n",
    "\n",
    "（原标题为《 “无症状”恐引第二波疫情？专家表示不是主因》）\n",
    "\"\"\"\n",
    "title = '无症状感染者恐引第二波疫情？专家：不是主因，关键看4月底'\n",
    "\n",
    "\n",
    "\n",
    "print(title)\n",
    "num = 10\n",
    "summary, html_summary,(sentences, score), feature_df= auto_summary(content, title,num,title_common=False,use_mmr=True)\n",
    "display(HTML(html_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
